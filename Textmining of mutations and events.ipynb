{
 "metadata": {
  "name": "Textmining of mutations and events"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As usual, we start doing some magic to load R scripts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmagic "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "dir = \"19-05-2014\"\n",
      "\n",
      "options(stringsAsFactors=F)\n",
      "\n",
      "mycon = gzcon(gzfile(paste(dir, \"buggy_traces.csv.gz\", sep=\"/\"), open=\"r\"))\n",
      "buggy_program_events = read.csv(textConnection(readLines(mycon)), sep=\"\\t\", header = F)\n",
      "\n",
      "\n",
      "mycon = gzcon(gzfile(paste(dir, \"robust_traces.csv.gz\", sep=\"/\"), open=\"r\"))\n",
      "robust_program_events = read.csv(textConnection(readLines(mycon)), sep=\"\\t\", header = F)\n",
      "\n",
      "print(nrow(robust_program_events))\n",
      "print(nrow(buggy_program_events))\n",
      "\n",
      "programs = c(levels(buggy_program_events[,1]),levels(robust_program_events[,1]))\n",
      "cats = factor(c(robust_program_events[,4], buggy_program_events[,4]), levels = c(\"R\",\"B\"))\n",
      "\n",
      "write.csv(programs,paste(dir,\"programs.csv\", sep=\"/\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "[1] 182\n",
        "[1] 546\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO: Add an explanation about program traces as documents.\n",
      "\n",
      "Now, we load the tm package and create the corpuses from the \"documents\". "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "library(tm)\n",
      "\n",
      "mut_corpus = Corpus(VectorSource(c(robust_program_events[,2],buggy_program_events[,2])))\n",
      "evs_corpus = Corpus(VectorSource(c(robust_program_events[,3],buggy_program_events[,3])))\n",
      "\n",
      "print(mut_corpus)\n",
      "print(evs_corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "A corpus with 728 text documents\n",
        "A corpus with 728 text documents\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, it is time to create the document matrixes, and convert them to data frames adding its correspondent classes. The function \"inspect\" to convert the document term matrix into a data frame prints some information that we don't care, so we discard printed messages in this step."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "library(\"RWeka\")\n",
      "options(mc.cores=1)\n",
      "\n",
      "\n",
      "mut_dm = DocumentTermMatrix(mut_corpus)\n",
      "\n",
      "sink(\"/dev/null\")\n",
      "\n",
      "mut_dm_df =  as.data.frame(inspect(mut_dm))\n",
      "rownames(mut_dm_df) = 1:nrow(mut_dm)\n",
      "mut_dm_df[\"class\"] = cats\n",
      "\n",
      "sink()\n",
      "\n",
      "BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2, delimiters=\" \"))\n",
      "evs_dm = DocumentTermMatrix(evs_corpus, control = list(bounds = list(global = c(5,Inf)), tokenize = BigramTokenizer))\n",
      "\n",
      "print(evs_dm)\n",
      "\n",
      "\n",
      "sink(\"/dev/null\")\n",
      "\n",
      "evs_dm_df =  (as.data.frame(inspect(evs_dm)))\n",
      "rownames(evs_dm_df) = 1:nrow(evs_dm)\n",
      "evs_dm_df[\"class\"] = cats\n",
      "    \n",
      "sink()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "A document-term matrix (728 documents, 1834 terms)\n",
        "\n",
        "Non-/sparse entries: 40274/1294878\n",
        "Sparsity           : 97%\n",
        "Maximal term length: 68 \n",
        "Weighting          : term frequency (tf)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To finish preparing the data, we need make sure we are using the same variables for all the corpuses in the mutation and events data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "# Mutation data\n",
      "\n",
      "mut_robust_cases = mut_dm_df[mut_dm_df$class == \"R\",]\n",
      "mut_buggy_cases  = mut_dm_df[mut_dm_df$class == \"B\",]\n",
      "\n",
      "# Event data\n",
      "\n",
      "evs_robust_cases = evs_dm_df[evs_dm_df$class == \"R\",]\n",
      "evs_buggy_cases  = evs_dm_df[evs_dm_df$class == \"B\",]\n",
      "\n",
      "both_robust_cases = cbind(mut_robust_cases[,names(mut_robust_cases) != \"class\"], evs_robust_cases)\n",
      "both_buggy_cases = cbind(mut_buggy_cases[,names(mut_buggy_cases) != \"class\"], evs_buggy_cases)\n",
      "\n",
      "print(nrow(both_robust_cases))\n",
      "print(nrow(both_buggy_cases))\n",
      "\n",
      "print(ncol(both_robust_cases))\n",
      "print(ncol(both_buggy_cases))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "[1] 397\n",
        "[1] 331\n",
        "[1] 2414\n",
        "[1] 2414\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "robust_cases = both_robust_cases\n",
      "buggy_cases = both_buggy_cases\n",
      "\n",
      "#rm(buggy_program_events)\n",
      "#gc()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "now, we are ready to select train and test.."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "train_size = 250\n",
      "test_size = nrow(buggy_cases) - train_size\n",
      "\n",
      "print(train_size)\n",
      "print(test_size)\n",
      "\n",
      "n = nrow(buggy_cases)\n",
      "rsample = sample(n)\n",
      "\n",
      "train_sample = rsample[1:(train_size)] \n",
      "test_sample = rsample[(train_size+1):(train_size+test_size)]\n",
      "\n",
      "#print(rsample)\n",
      "\n",
      "buggy_train = buggy_cases[train_sample,]\n",
      "buggy_test  = buggy_cases[test_sample,]\n",
      "\n",
      "print(nrow(buggy_train))\n",
      "print(nrow(buggy_test))\n",
      "\n",
      "# robust train and test\n",
      "\n",
      "n = nrow(robust_cases)\n",
      "rsample = sample(n)\n",
      "\n",
      "#print(rsample)\n",
      "\n",
      "# n cases are selected to keep the train dataset balanced\n",
      "train_sample = rsample[1:(train_size)]\n",
      "test_sample =  rsample[(train_size+1):(train_size+test_size)]\n",
      "more_test_sample = rsample[(train_size+test_size+1):n]\n",
      "\n",
      "robust_train = robust_cases[train_sample,]\n",
      "robust_test  = robust_cases[test_sample,]\n",
      "robust_more_test = robust_cases[more_test_sample,]\n",
      "\n",
      "print(nrow(robust_train))\n",
      "print(nrow(robust_test))\n",
      "\n",
      "train = rbind(buggy_train, robust_train)\n",
      "test  = rbind(buggy_test, robust_test)\n",
      "more_test = robust_more_test\n",
      "\n",
      "#print(more_test[1,])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "[1] 250\n",
        "[1] 81\n",
        "[1] 250\n",
        "[1] 81\n",
        "[1] 250\n",
        "[1] 81\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, we are ready to train and test a knn model:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "or a SVM .."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "library(\"e1071\")\n",
      "library(\"caret\")\n",
      "\n",
      "xy_train = train\n",
      "xy_train[,\"class\"] = factor(train[,\"class\"])\n",
      "x_test = test[,names(test) != \"class\"]\n",
      "y_test  = test[,\"class\"]\n",
      "\n",
      "x_more_test = more_test[,names(test) != \"class\"]\n",
      "y_more_test  = more_test[,\"class\"]\n",
      "\n",
      "#m = svm(class ~., data=xy_train, gamma=0.1, cost=10)#, kernel=\"linear\")\n",
      "#m = svm(class ~., data=xy_train, gamma=0.001, cost=100)#, kernel=\"linear\")\n",
      "#scores = t(abs(t(m$coefs) %*% m$SV))\n",
      "#inds = sort(scores, decreasing=TRUE, index.return = TRUE)$i\n",
      "#print(scores[inds,])\n",
      "\n",
      "#m = tune.svm(class~., data = xy_train,  gamma = 10^(-5:-1), cost = 10^(1:2))\n",
      "#print(summary(m))\n",
      "#m = m$best.model\n",
      "\n",
      "m = svm(class ~., data=xy_train, gamma=0.01, cost=100)#, kernel=\"linear\")\n",
      "\n",
      "z = predict(m,x_test)\n",
      "#print(z)\n",
      "#print(y_test)\n",
      "print(confusionMatrix(table(pred=z, true=y_test)))\n",
      "\n",
      "z = predict(m,x_more_test)\n",
      "#print(z)\n",
      "print(confusionMatrix(table(pred=z, true=y_more_test)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "Loading required package: lattice\n",
        "Loading required package: ggplot2\n",
        "Confusion Matrix and Statistics\n",
        "\n",
        "    true\n",
        "pred  R  B\n",
        "   R 59 24\n",
        "   B 22 57\n",
        "                                       \n",
        "               Accuracy : 0.716        \n",
        "                 95% CI : (0.64, 0.784)\n",
        "    No Information Rate : 0.5          \n",
        "    P-Value [Acc > NIR] : 1.835e-08    \n",
        "                                       \n",
        "                  Kappa : 0.4321       \n",
        " Mcnemar's Test P-Value : 0.8828       \n",
        "                                       \n",
        "            Sensitivity : 0.7284       \n",
        "            Specificity : 0.7037       \n",
        "         Pos Pred Value : 0.7108       \n",
        "         Neg Pred Value : 0.7215       \n",
        "             Prevalence : 0.5000       \n",
        "         Detection Rate : 0.3642       \n",
        "   Detection Prevalence : 0.5123       \n",
        "      Balanced Accuracy : 0.7160       \n",
        "                                       \n",
        "       'Positive' Class : R            \n",
        "                                       \n",
        "Confusion Matrix and Statistics\n",
        "\n",
        "    true\n",
        "pred  R  B\n",
        "   R 55  0\n",
        "   B 11  0\n",
        "                                          \n",
        "               Accuracy : 0.8333          \n",
        "                 95% CI : (0.7213, 0.9138)\n",
        "    No Information Rate : 1               \n",
        "    P-Value [Acc > NIR] : 1.000000        \n",
        "                                          \n",
        "                  Kappa : 0               \n",
        " Mcnemar's Test P-Value : 0.002569        \n",
        "                                          \n",
        "            Sensitivity : 0.8333          \n",
        "            Specificity :     NA          \n",
        "         Pos Pred Value :     NA          \n",
        "         Neg Pred Value :     NA          \n",
        "             Prevalence : 1.0000          \n",
        "         Detection Rate : 0.8333          \n",
        "   Detection Prevalence : 0.8333          \n",
        "      Balanced Accuracy :     NA          \n",
        "                                          \n",
        "       'Positive' Class : R               \n",
        "                                          \n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "scores = t(abs(t(m$coefs) %*% m$SV))\n",
      "inds = sort(scores, decreasing=TRUE, index.return = TRUE)$i\n",
      "print(names(scores[inds,][1:50]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        " [1] \"X.strlen.ret_val.num32b8.strlen.0.hptr32.\"                  \n",
        " [2] \"X.strcpy.0.hptr32.strcpy.ret_val.hptr32.\"                   \n",
        " [3] \"X.memcpy.1.hptr32.memcpy.0.hptr32.\"                         \n",
        " [4] \"X.memcpy.ret_val.hptr32.memcpy.2.num32b8.\"                  \n",
        " [5] \"X.memcpy.2.num32b8.memcpy.1.hptr32.\"                        \n",
        " [6] \"X.strlen.0.gptr32.strlen.ret_val.num32b8.\"                  \n",
        " [7] \"X.memcpy.0.hptr32.memcpy.ret_val.hptr32.\"                   \n",
        " [8] \"X.strcpy.1.hptr32.strcpy.0.hptr32.\"                         \n",
        " [9] \"X.strcpy.ret_val.hptr32.strlen.ret_val.num32b8.\"            \n",
        "[10] \"X.strlen.0.hptr32.strcpy.1.hptr32.\"                         \n",
        "[11] \"X.strlen.ret_val.num32b8.strlen.0.gptr32.\"                  \n",
        "[12] \"X.__ctype_b_loc.ret_val.fptr32.__ctype_b_loc.0.top32.\"      \n",
        "[13] \"X.strchr.ret_val.nptr32.strchr.1.num32b8.\"                  \n",
        "[14] \"X.strchr.0.lptr32.strchr.ret_val.nptr32.\"                   \n",
        "[15] \"X.strchr.1.num32b8.strchr.0.lptr32.\"                        \n",
        "[16] \"X.__ctype_b_loc.0.top32.__ctype_b_loc.ret_val.fptr32.\"      \n",
        "[17] \"X.memcpy.2.num32b8.memcpy.0.hptr32.\"                        \n",
        "[18] \"X.strlen.ret_val.num32b8.strlen.0.lptr32.\"                  \n",
        "[19] \"X.fread.0.sptr32.fread.3.hptr32.\"                           \n",
        "[20] \"X.fread.3.hptr32.fread.1.num32b8.\"                          \n",
        "[21] \"X.realloc.ret_val.hptr32.realloc.1.num32b8.\"                \n",
        "[22] \"X.fread.2.num32b8.fread.ret_val.num32b0.\"                   \n",
        "[23] \"X.fread.ret_val.num32b0.fread.0.sptr32.\"                    \n",
        "[24] \"X.memcpy.ret_val.hptr32.memcpy.1.lptr32.\"                   \n",
        "[25] \"X.memcpy.1.lptr32.memcpy.2.num32b8.\"                        \n",
        "[26] \"X.tolower.0.num32b8.tolower.ret_val.num32b8.\"               \n",
        "[27] \"X.tolower.ret_val.num32b8.tolower.0.num32b8.\"               \n",
        "[28] \"X.realloc.1.num32b8.realloc.0.nptr32.\"                      \n",
        "[29] \"X.memcpy.0.hptr32.strlen.ret_val.num32b8.\"                  \n",
        "[30] \"X.strlen.0.hptr32.strlen.ret_val.num32b8.\"                  \n",
        "[31] \"X.memset.0.hptr32.memset.ret_val.hptr32.\"                   \n",
        "[32] \"X.__errno_location.ret_val.fptr32.__errno_location.0.top32.\"\n",
        "[33] \"X.__errno_location.0.top32.realloc.ret_val.hptr32.\"         \n",
        "[34] \"X.memset.2.num32b16.memset.0.hptr32.\"                       \n",
        "[35] \"X.memset.ret_val.hptr32.memset.1.num32b0.\"                  \n",
        "[36] \"X.realloc.0.nptr32.memcpy.ret_val.hptr32.\"                  \n",
        "[37] \"X.memset.1.num32b0.fread.2.num32b8.\"                        \n",
        "[38] \"X.fread.1.num32b8.memset.2.num32b16.\"                       \n",
        "[39] \"X.fputc.ret_val.num32b8.fprintf.1.gptr32.\"                  \n",
        "[40] \"X.fgets.0.sptr32.fgets.1.num32b16.\"                         \n",
        "[41] \"X.fgets.1.num32b16.fgets.ret_val.sptr32.\"                   \n",
        "[42] \"X.fgets.2.hptr32.fgets.0.sptr32.\"                           \n",
        "[43] \"X.fprintf.1.gptr32.fprintf.0.lptr32.\"                       \n",
        "[44] \"X.fprintf.0.lptr32.fprintf.ret_val.num32b8.\"                \n",
        "[45] \"X.vfprintf.2.sptr32.vfprintf.0.lptr32.\"                     \n",
        "[46] \"X.vfprintf.0.lptr32.vfprintf.ret_val.num32b8.\"              \n",
        "[47] \"X.vfprintf.1.gptr32.vfprintf.2.sptr32.\"                     \n",
        "[48] \"X.fprintf.ret_val.num32b8.vfprintf.1.gptr32.\"               \n",
        "[49] \"X.vfprintf.ret_val.num32b8.fputc.0.num32b8.\"                \n",
        "[50] \"X.fputc.0.num32b8.fputc.1.lptr32.\"                          \n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "m_vars = names(xy_train)\n",
      "\n",
      "save(m_vars, file=paste(dir, \"svms\", \"mvars.data\", sep=\"/\"))\n",
      "save(m, file=paste(dir, \"svms\", \"mutation-event-classifier.svm\", sep=\"/\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}