{
 "metadata": {
  "name": "textmining_19-05-2014"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As usual, we start doing some magic to load R scripts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmagic "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "During startup - Warning messages:\n",
        "1: Setting LC_TIME failed, using \"C\" \n",
        "2: Setting LC_MONETARY failed, using \"C\" \n",
        "3: Setting LC_PAPER failed, using \"C\" \n",
        "4: Setting LC_MEASUREMENT failed, using \"C\" \n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "dir = \"19-05-2014\"\n",
      "\n",
      "mycon = gzcon(gzfile(paste(dir, \"buggy_traces.csv.gz\", sep=\"/\"), open=\"r\"))\n",
      "buggy_program_events = read.csv(textConnection(readLines(mycon)), sep=\"\\t\", header = F)\n",
      "\n",
      "\n",
      "mycon = gzcon(gzfile(paste(dir, \"robust_traces.csv.gz\", sep=\"/\"), open=\"r\"))\n",
      "robust_program_events = read.csv(textConnection(readLines(mycon)), sep=\"\\t\", header = F)\n",
      "\n",
      "print(nrow(robust_program_events))\n",
      "print(nrow(buggy_program_events))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "[1] 182\n",
        "[1] 546\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO: Add an explanation about program traces as documents.\n",
      "\n",
      "Now, we load the tm package and create the corpuses from the \"documents\". "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "library(tm)\n",
      "\n",
      "mut_robust_corpus = Corpus(VectorSource(robust_program_events[,2]))\n",
      "mut_buggy_corpus  = Corpus(VectorSource(buggy_program_events[,2]))\n",
      "\n",
      "evs_robust_corpus = Corpus(VectorSource(robust_program_events[,3]))\n",
      "evs_buggy_corpus  = Corpus(VectorSource(buggy_program_events[,3]))\n",
      "\n",
      "\n",
      "print(mut_robust_corpus)\n",
      "print(mut_buggy_corpus)\n",
      "\n",
      "print(evs_robust_corpus)\n",
      "print(evs_buggy_corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "A corpus with 182 text documents\n",
        "A corpus with 546 text documents\n",
        "A corpus with 182 text documents\n",
        "A corpus with 546 text documents\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, it is time to create the document matrixes, and convert them to data frames adding its correspondent classes. The function \"inspect\" to convert the document term matrix into a data frame prints some information that we don't care, so we discard printed messages in this step."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "mut_robust_dm = DocumentTermMatrix(mut_robust_corpus)\n",
      "mut_buggy_dm  = DocumentTermMatrix(mut_buggy_corpus)\n",
      "\n",
      "sink(\"/dev/null\")\n",
      "\n",
      "mut_robust_dm_df =  as.data.frame(inspect(mut_robust_dm))\n",
      "rownames(mut_robust_dm_df) = 1:nrow(mut_robust_dm)\n",
      "mut_robust_dm_df[\"class\"] = robust_program_events[,4]\n",
      "    \n",
      "mut_buggy_dm_df =  as.data.frame(inspect(mut_buggy_dm))\n",
      "rownames(mut_buggy_dm_df) = 1:nrow(mut_buggy_dm)\n",
      "mut_buggy_dm_df[\"class\"] = buggy_program_events[,4]\n",
      "\n",
      "sink()\n",
      "\n",
      "evs_robust_dm = DocumentTermMatrix(evs_robust_corpus)\n",
      "evs_buggy_dm  = DocumentTermMatrix(evs_buggy_corpus)\n",
      "\n",
      "sink(\"/dev/null\")\n",
      "\n",
      "evs_robust_dm_df =  as.data.frame(inspect(evs_robust_dm))\n",
      "rownames(evs_robust_dm_df) = 1:nrow(evs_robust_dm)\n",
      "evs_robust_dm_df[\"class\"] = robust_program_events[,4]#\"robust\"\n",
      "    \n",
      "evs_buggy_dm_df =  as.data.frame(inspect(evs_buggy_dm))\n",
      "rownames(evs_buggy_dm_df) = 1:nrow(evs_buggy_dm)\n",
      "evs_buggy_dm_df[\"class\"] = buggy_program_events[,4] #\"buggy\"\n",
      "\n",
      "    \n",
      "sink()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To finish preparing the data, we need make sure we are using the same variables for all the corpuses in the mutation and events data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "# Mutation data\n",
      "\n",
      "library(plyr)\n",
      "\n",
      "mut_dm_df = rbind.fill(mut_robust_dm_df, mut_buggy_dm_df)\n",
      "\n",
      "mut_dm_df[is.na(mut_dm_df)] = 0\n",
      "\n",
      "mut_robust_cases = mut_dm_df[mut_dm_df$class == \"R\",]\n",
      "mut_buggy_cases  = mut_dm_df[mut_dm_df$class == \"B\",]\n",
      "\n",
      "# Event data\n",
      "\n",
      "evs_dm_df = rbind.fill(evs_robust_dm_df, evs_buggy_dm_df)\n",
      "\n",
      "evs_dm_df[is.na(evs_dm_df)] = 0\n",
      "\n",
      "evs_robust_cases = evs_dm_df[evs_dm_df$class == \"R\",]\n",
      "evs_buggy_cases  = evs_dm_df[evs_dm_df$class == \"B\",]\n",
      "\n",
      "#print(rownames(mut_robust_cases))\n",
      "#print(rownames(evs_robust_cases))\n",
      "\n",
      "#print(rownames(mut_robust_cases) %in% rownames(evs_robust_cases))\n",
      "both_robust_cases = cbind(mut_robust_cases[,names(mut_robust_cases) != \"class\"], evs_robust_cases)\n",
      "both_buggy_cases = cbind(mut_buggy_cases[,names(mut_buggy_cases) != \"class\"], evs_buggy_cases)\n",
      "\n",
      "print(nrow(robust_cases))\n",
      "print(nrow(buggy_cases))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "[1] 397\n",
        "[1] 331\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "robust_cases = mut_robust_cases\n",
      "buggy_cases = mut_buggy_cases"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "now, we are ready to select train and test.."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "train_size = 250\n",
      "test_size = nrow(buggy_cases) - train_size\n",
      "\n",
      "print(train_size)\n",
      "print(test_size)\n",
      "\n",
      "n = nrow(buggy_cases)\n",
      "rsample = sample(n)\n",
      "\n",
      "train_sample = rsample[1:(train_size)] \n",
      "test_sample = rsample[(train_size+1):(train_size+test_size)]\n",
      "\n",
      "#print(rsample)\n",
      "\n",
      "buggy_train = buggy_cases[train_sample,]\n",
      "buggy_test  = buggy_cases[test_sample,]\n",
      "\n",
      "print(nrow(buggy_train))\n",
      "print(nrow(buggy_test))\n",
      "\n",
      "# robust train and test\n",
      "\n",
      "n = nrow(robust_cases)\n",
      "rsample = sample(n)\n",
      "\n",
      "#print(rsample)\n",
      "\n",
      "# n cases are selected to keep the train dataset balanced\n",
      "train_sample = rsample[1:(train_size)]\n",
      "test_sample =  rsample[(train_size+1):(train_size+test_size)]\n",
      "more_test_sample = rsample[(train_size+test_size+1):n]\n",
      "\n",
      "robust_train = robust_cases[train_sample,]\n",
      "robust_test  = robust_cases[test_sample,]\n",
      "robust_more_test = robust_cases[more_test_sample,]\n",
      "\n",
      "print(nrow(robust_train))\n",
      "print(nrow(robust_test))\n",
      "\n",
      "train = rbind(buggy_train, robust_train)\n",
      "test  = rbind(buggy_test, robust_test)\n",
      "more_test = robust_more_test\n",
      "\n",
      "#print(more_test[1,])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "[1] 250\n",
        "[1] 81\n",
        "[1] 250\n",
        "[1] 81\n",
        "[1] 250\n",
        "[1] 81\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, we are ready to train and test a knn model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "#print(round(importance(rf),2))\n",
      "\n",
      "library(\"class\")\n",
      "\n",
      "x_train = train[,names(train) != \"class\"]\n",
      "x_test  = test[,names(test) != \"class\"]\n",
      "y_train = train[,\"class\"]\n",
      "y_test  = test[,\"class\"]\n",
      "\n",
      "#print(y)\n",
      "for (k in 1:10) {\n",
      "  print(k)\n",
      "  z = knn(x_train,x_test, y_train, k, use.all = FALSE)\n",
      "  #print(z)\n",
      "  #print(test[,\"class\"])\n",
      "  print(table(z, y_test))\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "[1] 1\n",
        "   y_test\n",
        "z    R  B\n",
        "  R 30 10\n",
        "  B 51 71\n",
        "[1] 2\n",
        "   y_test\n",
        "z    R  B\n",
        "  R 49 23\n",
        "  B 32 58\n",
        "[1] 3\n",
        "   y_test\n",
        "z    R  B\n",
        "  R 49 17\n",
        "  B 32 64\n",
        "[1] 4\n",
        "   y_test\n",
        "z    R  B\n",
        "  R 42 19\n",
        "  B 39 62\n",
        "[1] 5\n",
        "   y_test\n",
        "z    R  B\n",
        "  R 37 16\n",
        "  B 44 65\n",
        "[1] 6\n",
        "   y_test\n",
        "z    R  B\n",
        "  R 38 10\n",
        "  B 43 71\n",
        "[1] 7\n",
        "   y_test\n",
        "z    R  B\n",
        "  R 40 12\n",
        "  B 41 69\n",
        "[1] 8\n",
        "   y_test\n",
        "z    R  B\n",
        "  R 37 11\n",
        "  B 44 70\n",
        "[1] 9\n",
        "   y_test\n",
        "z    R  B\n",
        "  R 36 10\n",
        "  B 45 71\n",
        "[1] 10\n",
        "   y_test\n",
        "z    R  B\n",
        "  R 35 10\n",
        "  B 46 71\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "or a SVM .."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "library(\"e1071\")\n",
      "library(\"caret\")\n",
      "\n",
      "xy_train = train\n",
      "xy_train[,\"class\"] = factor(train[,\"class\"])\n",
      "x_test = test[,names(test) != \"class\"]\n",
      "y_test  = test[,\"class\"]\n",
      "\n",
      "x_more_test = more_test[,names(test) != \"class\"]\n",
      "y_more_test  = more_test[,\"class\"]\n",
      "\n",
      "m = svm(class ~., data=xy_train, gamma=0.1, cost=10)#, kernel=\"linear\")\n",
      "#m = svm(class ~., data=xy_train, gamma=0.001, cost=100)#, kernel=\"linear\")\n",
      "#scores = t(abs(t(m$coefs) %*% m$SV))\n",
      "#inds = sort(scores, decreasing=TRUE, index.return = TRUE)$i\n",
      "#print(scores[inds,])\n",
      "\n",
      "#m = tune.svm(class~., data = xy_train,  gamma = 10^(-3:-1), cost = 10^(1:2))\n",
      "#print(summary(m))\n",
      "\n",
      "z = predict(m,x_test)\n",
      "#print(z)\n",
      "print(confusionMatrix(table(pred=z, true=y_test)))\n",
      "\n",
      "z = predict(m,x_more_test)\n",
      "#print(z)\n",
      "print(table(pred=z, true=y_more_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "Confusion Matrix and Statistics\n",
        "\n",
        "    true\n",
        "pred  R  B\n",
        "   R 61 22\n",
        "   B 20 59\n",
        "                                          \n",
        "               Accuracy : 0.7407          \n",
        "                 95% CI : (0.6661, 0.8063)\n",
        "    No Information Rate : 0.5             \n",
        "    P-Value [Acc > NIR] : 3.399e-10       \n",
        "                                          \n",
        "                  Kappa : 0.4815          \n",
        " Mcnemar's Test P-Value : 0.8774          \n",
        "                                          \n",
        "            Sensitivity : 0.7531          \n",
        "            Specificity : 0.7284          \n",
        "         Pos Pred Value : 0.7349          \n",
        "         Neg Pred Value : 0.7468          \n",
        "             Prevalence : 0.5000          \n",
        "         Detection Rate : 0.3765          \n",
        "   Detection Prevalence : 0.5123          \n",
        "      Balanced Accuracy : 0.7407          \n",
        "                                          \n",
        "       'Positive' Class : R               \n",
        "                                          \n",
        "    true\n",
        "pred  R  B\n",
        "   R 44  0\n",
        "   B 22  0\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "scores = t(abs(t(m$coefs) %*% m$SV))\n",
      "inds = sort(scores, decreasing=TRUE, index.return = TRUE)$i\n",
      "print(scores[inds,][1:25])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "   X.new.16.   X.new.145.    X.pos.33.   X.new.130.   X.old.179.    X.new.65. \n",
        "   10.677359     9.994599     9.846344     8.534919     8.278906     8.241497 \n",
        "  X.new.179.    X.old.23.   X.old.148.    X.pos.67.   X.old.189. X.size.1800. \n",
        "    8.226547     8.100437     8.041618     7.997184     7.977908     7.851645 \n",
        "  X.old.250.    X.old.75.    X.old.70. X.size.5300.   X.old.118.   X.new.185. \n",
        "    7.850725     7.832921     7.721126     7.371158     7.096834     6.982325 \n",
        "  X.new.129.     X.new.2.   X.new.101.    X.old.19.     X.old.1.     X.new.8. \n",
        "    6.922841     6.875224     6.544013     6.461215     6.218256     6.168560 \n",
        "X.size.1600. \n",
        "    6.046306 \n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "m_vars = names(xy_train)\n",
      "#print(m_vars)\n",
      "save(m_vars, file=paste(dir, \"svms\", \"mvars.data\", sep=\"/\"))\n",
      "save(m, file=paste(dir, \"svms\", \"mutation-classifier.svm\", sep=\"/\"))\n",
      "#write.svm(m, svm.file = paste(dir, \"svms\", \"mutation-classifier.svm\", sep=\"/\"), scale.file = paste(dir, \"svms\", \"mutation-classifier.scale\", sep=\"/\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    }
   ],
   "metadata": {}
  }
 ]
}