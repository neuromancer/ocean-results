{
 "metadata": {
  "name": "Training-Testing-25"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As usual, we start doing some magic to load R scripts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmagic "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "#library(\"RWeka\")\n",
      "library(\"e1071\")\n",
      "library(\"kernlab\")\n",
      "library(\"caret\")\n",
      "library(\"tm\")\n",
      "\n",
      "options(mc.cores=1)\n",
      "\n",
      "dir = \"25-05-2014\"\n",
      "\n",
      "options(stringsAsFactors=F)\n",
      "\n",
      "mycon = gzcon(gzfile(paste(dir, \"filtered_traces.csv.gz\", sep=\"/\"), open=\"r\"))\n",
      "buggy_program_events = read.csv(textConnection(readLines(mycon)), sep=\"\\t\", header = F)\n",
      "\n",
      "print(nrow(buggy_program_events))\n",
      "\n",
      "#programs = c(levels(buggy_program_events[,1]))\n",
      "cats = factor(c(buggy_program_events[,4]), levels = c(\"R\",\"B\"))\n",
      "events = buggy_program_events[,3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "Loading required package: lattice\n",
        "Loading required package: ggplot2\n",
        "[1] 1999\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO: Add an explanation about program traces as documents.\n",
      "\n",
      "Now, we load the tm package and create the corpuses from the \"documents\". "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "mut_corpus = Corpus(VectorSource(c(buggy_program_events[,2])))\n",
      "#evs_corpus = Corpus(VectorSource(c(buggy_program_events[,3])))\n",
      "\n",
      "print(mut_corpus)\n",
      "#print(evs_corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "A corpus with 1999 text documents\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, it is time to create the document matrixes, and convert them to data frames adding its correspondent classes. The function \"inspect\" to convert the document term matrix into a data frame prints some information that we don't care, so we discard printed messages in this step."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "mut_dm = DocumentTermMatrix(mut_corpus)\n",
      "\n",
      "sink(\"/dev/null\")\n",
      "\n",
      "mut_dm_df =  as.data.frame(inspect(mut_dm))\n",
      "#rownames(mut_dm_df) = 1:nrow(mut_dm)\n",
      "mut_dm_df[\"events\"] = events\n",
      "mut_dm_df[\"class\"] = cats\n",
      "\n",
      "sink()\n",
      "\n",
      "#BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2, delimiters=\" \"))\n",
      "#evs_dm = DocumentTermMatrix(evs_corpus, control = list(bounds = list(global = c(5,Inf)), tokenize = BigramTokenizer))\n",
      "#print(evs_dm)\n",
      "\n",
      "#sink(\"/dev/null\")\n",
      "\n",
      "#sorted_dm = sort(colSums(as.matrix(evs_dm)), decreasing=TRUE)\n",
      "\n",
      "#evs_dm_df =  as.data.frame(inspect(evs_dm))\n",
      "#evs_dm_df[\"class\"] = cats\n",
      "\n",
      "#sink()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To finish preparing the data, we need make sure we are using the same variables for all the corpuses in the mutation and events data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "# Mutation data\n",
      "\n",
      "mut_robust_cases = mut_dm_df[mut_dm_df$class == \"R\",]\n",
      "mut_buggy_cases  = mut_dm_df[mut_dm_df$class == \"B\",]\n",
      "\n",
      "# Event data\n",
      "\n",
      "#evs_robust_cases = evs_dm_df[evs_dm_df$class == \"R\",]\n",
      "#evs_buggy_cases  = evs_dm_df[evs_dm_df$class == \"B\",]\n",
      "\n",
      "#both_robust_cases = cbind(mut_robust_cases[,names(mut_robust_cases) != \"class\"], evs_robust_cases)\n",
      "#both_buggy_cases = cbind(mut_buggy_cases[,names(mut_buggy_cases) != \"class\"], evs_buggy_cases)\n",
      "\n",
      "#print(nrow(both_robust_cases))\n",
      "#print(nrow(both_buggy_cases))\n",
      "\n",
      "#print(ncol(both_robust_cases))\n",
      "#print(ncol(both_buggy_cases))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "robust_cases = mut_robust_cases\n",
      "buggy_cases = mut_buggy_cases\n",
      "\n",
      "#rm(buggy_program_events)\n",
      "#gc()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "now, we are ready to select train and test.."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "train_size = 500\n",
      "test_size = nrow(buggy_cases) - train_size\n",
      "\n",
      "print(train_size)\n",
      "print(test_size)\n",
      "\n",
      "n = nrow(buggy_cases)\n",
      "rsample = 1:n\n",
      "#rsample = sample(n)\n",
      "\n",
      "train_sample = rsample[1:(train_size)] \n",
      "test_sample = rsample[(train_size+1):(train_size+test_size)]\n",
      "\n",
      "#print(rsample)\n",
      "\n",
      "buggy_train = buggy_cases[train_sample,]\n",
      "buggy_test  = buggy_cases[test_sample,]\n",
      "\n",
      "print(nrow(buggy_train))\n",
      "print(nrow(buggy_test))\n",
      "\n",
      "# robust train and test\n",
      "\n",
      "n = nrow(robust_cases)\n",
      "rsample = 1:n\n",
      "#rsample = sample(n)\n",
      "\n",
      "#print(rsample)\n",
      "\n",
      "# n cases are selected to keep the train dataset balanced\n",
      "train_sample = rsample[1:(train_size)]\n",
      "test_sample =  rsample[(train_size+1):(train_size+test_size)]\n",
      "more_test_sample = rsample[(train_size+test_size+1):n]\n",
      "\n",
      "robust_train = robust_cases[train_sample,]\n",
      "robust_test  = robust_cases[test_sample,]\n",
      "robust_more_test = robust_cases[more_test_sample,]\n",
      "\n",
      "print(nrow(robust_train))\n",
      "print(nrow(robust_test))\n",
      "\n",
      "train = rbind(buggy_train, robust_train)\n",
      "test  = rbind(buggy_test, robust_test)\n",
      "#more_test = robust_more_test\n",
      "\n",
      "xy_train = train\n",
      "xy_test  = test\n",
      "#xy_train[,\"class\"] = factor(train[,\"class\"])\n",
      "x_test = test[,names(test) != \"class\"]\n",
      "y_test  = test[,\"class\"]\n",
      "\n",
      "#print(names(xy_train))\n",
      "#print(names(xy_test))\n",
      "#print(ncol(x_test[100,]))\n",
      "#print(ncol(y_test[100]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "[1] 500\n",
        "[1] 221\n",
        "[1] 500\n",
        "[1] 221\n",
        "[1] 500\n",
        "[1] 221\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, we are ready to train and test a knn model:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "or a SVM .."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "#mut_vars = setdiff(names(xy_train),c(\"events\"))\n",
      "mut_vars = 1:652\n",
      "x_vars = 1:653\n",
      "#print(mut_vars[1:652])\n",
      "\n",
      "mker = function(x,y) {crossprod(x, y)}\n",
      "\n",
      "mker = crossprod\n",
      "class(mker) <- \"kernel\"\n",
      "\n",
      "print(names(xy_train)[652])\n",
      "print(names(xy_test)[652])\n",
      "\n",
      "#print(names(xy_train) == names(x_test))\n",
      "#print(names(xy_train))\n",
      "\n",
      "svp = ksvm(class~., data = xy_train[,names(xy_train) != \"events\"],kernel=mker,cross=5,tol = 0.01, shrinking = FALSE)\n",
      "#svp = ksvm(x = xy_train[,names(xy_train) != \"class\"], y = xy_train[,\"class\"] ,kernel=vanilladot(),cross=5)\n",
      "print(svp)\n",
      "#print(warnings())\n",
      "#z = predict(svp,x_test[,names(x_test) != \"events\"])\n",
      "#print(confusionMatrix(table(pred=z, true=y_test)))\n",
      "\n",
      "#print(as.vector(mut_dm_df[1,]))\n",
      "#print(is(as.vector(mut_dm_df[1,], mode='numeric'),\"vector\"))\n",
      "#print(mker(test[1,],test[1,]))\n",
      "\n",
      "#stringkern <- stringdot(type = \"string\")\n",
      "\n",
      "#x = inspect(evs_corpus[1:10])\n",
      "#print(x)\n",
      "#print([[1]])\n",
      "#kpc <- kpca(x,kernel=stringkern,scale=c())\n",
      "#stringCl <- specc(evs_corpus, 2, kernel = stringkern)\n",
      "\n",
      "#print(kpc)\n",
      "#plot(rotated(kpc))\n",
      "\n",
      "#xy_train[,setdiff(names(xy_train),c(\"class\"))] =  sign(xy_train[,setdiff(names(xy_train),c(\"class\"))])\n",
      "#x_test[,setdiff(names(x_test),c(\"class\"))] = sign(x_test[,setdiff(names(x_test),c(\"class\"))])\n",
      "#print(x_test[1:2,])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "mseq = c(1)#seq(25,800,25)\n",
      "res = c()\n",
      "\n",
      "for (n in mseq){\n",
      "  #exc_vars = names(tail(sorted_dm, -n))\n",
      "  #inc_vars = names(xy_train)[!(names(xy_train) %in% exc_vars)]\n",
      "  \n",
      "  #m = svm(class ~., data=xy_train[,inc_vars], gamma=0.01, cost=1)\n",
      "  \n",
      "  tcont = tune.control(sampling='fix')\n",
      "  m = tune.svm(class~., data = xy_train, validation.x = x_test, validation.y = y_test, gamma = 10^(-5:-1), cost = 10^(-1:3), tunecontrol=tcont)\n",
      "  print(summary(m))\n",
      "  m = m$best.model\n",
      "  \n",
      "  z = predict(m,x_test)\n",
      "  \n",
      "  #print(m)\n",
      " \n",
      "  res = c(res,confusionMatrix(table(pred=z, true=y_test))$overall[1])\n",
      "  \n",
      "  #z = predict(m,x_more_test)\n",
      "  #print(confusionMatrix(table(pred=z, true=y_more_test))$overall[1])\n",
      "}\n",
      "\n",
      "print(data.frame(n=mseq, acc=res))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "\n",
        "Parameter tuning of \u2018svm\u2019:\n",
        "\n",
        "- sampling method: fixed training/validation set \n",
        "\n",
        "- best parameters:\n",
        " gamma cost\n",
        "   0.1    1\n",
        "\n",
        "- best performance: 0.2963801 \n",
        "\n",
        "- Detailed performance results:\n",
        "   gamma  cost     error dispersion\n",
        "1  1e-05 1e-01 0.3144796         NA\n",
        "2  1e-04 1e-01 0.3144796         NA\n",
        "3  1e-03 1e-01 0.3144796         NA\n",
        "4  1e-02 1e-01 0.3144796         NA\n",
        "5  1e-01 1e-01 0.3642534         NA\n",
        "6  1e-05 1e+00 0.3144796         NA\n",
        "7  1e-04 1e+00 0.3144796         NA\n",
        "8  1e-03 1e+00 0.3144796         NA\n",
        "9  1e-02 1e+00 0.3642534         NA\n",
        "10 1e-01 1e+00 0.2963801         NA\n",
        "11 1e-05 1e+01 0.3144796         NA\n",
        "12 1e-04 1e+01 0.3144796         NA\n",
        "13 1e-03 1e+01 0.3642534         NA\n",
        "14 1e-02 1e+01 0.3009050         NA\n",
        "15 1e-01 1e+01 0.3416290         NA\n",
        "16 1e-05 1e+02 0.3144796         NA\n",
        "17 1e-04 1e+02 0.3642534         NA\n",
        "18 1e-03 1e+02 0.3054299         NA\n",
        "19 1e-02 1e+02 0.3552036         NA\n",
        "20 1e-01 1e+02 0.3416290         NA\n",
        "21 1e-05 1e+03 0.3642534         NA\n",
        "22 1e-04 1e+03 0.3076923         NA\n",
        "23 1e-03 1e+03 0.3665158         NA\n",
        "24 1e-02 1e+03 0.3710407         NA\n",
        "25 1e-01 1e+03 0.3416290         NA\n",
        "\n",
        "         n       acc\n",
        "Accuracy 1 0.7036199\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "\n",
      "#plot(data.frame(n=mseq, err=res))\n",
      "scores = t(abs(t(m$coefs) %*% m$SV))\n",
      "inds = sort(scores, decreasing=TRUE, index.return = TRUE)$i\n",
      "print(names(scores[inds,][1:50]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        " [1] \"X.type.con.\"  \"X.new.45.\"    \"X.new.0.\"     \"X.old.35.\"    \"X.new.115.\"  \n",
        " [6] \"X.new.4.\"     \"X.old.65.\"    \"X.type.ext.\"  \"X.old.115.\"   \"X.old.114.\"  \n",
        "[11] \"X.new.112.\"   \"X.old.108.\"   \"X.new.114.\"   \"X.pos.66.\"    \"X.size.4100.\"\n",
        "[16] \"X.old.112.\"   \"X.type.mod.\"  \"X.old.101.\"   \"X.old.91.\"    \"X.new.61.\"   \n",
        "[21] \"X.new.120.\"   \"X.old.45.\"    \"X.pos.4.\"     \"X.new.47.\"    \"X.new.65.\"   \n",
        "[26] \"X.new.8.\"     \"X.size.7600.\" \"X.new.111.\"   \"X.size.1600.\" \"X.old.193.\"  \n",
        "[31] \"X.new.101.\"   \"X.new.105.\"   \"X.new.25.\"    \"X.new.68.\"    \"X.new.91.\"   \n",
        "[36] \"X.old.164.\"   \"X.old.174.\"   \"X.old.48.\"    \"X.old.84.\"    \"X.pos.71.\"   \n",
        "[41] \"X.size.1400.\" \"X.size.7300.\" \"X.old.138.\"   \"X.size.3100.\" \"X.old.110.\"  \n",
        "[46] \"X.new.10.\"    \"X.new.109.\"   \"X.old.11.\"    \"X.old.58.\"    \"X.new.58.\"   \n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "m_vars = names(xy_train)\n",
      "\n",
      "save(m_vars, file=paste(dir, \"svms\", \"mvars.data\", sep=\"/\"))\n",
      "save(m, file=paste(dir, \"svms\", \"mutation-event-classifier.svm\", sep=\"/\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}