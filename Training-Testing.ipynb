{
 "metadata": {
  "name": "Training-Testing"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As usual, we start doing some magic to load R scripts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmagic "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "dir = \"19-05-2014\"\n",
      "\n",
      "options(stringsAsFactors=F)\n",
      "\n",
      "mycon = gzcon(gzfile(paste(dir, \"buggy_traces.csv.gz\", sep=\"/\"), open=\"r\"))\n",
      "buggy_program_events = read.csv(textConnection(readLines(mycon)), sep=\"\\t\", header = F)\n",
      "\n",
      "\n",
      "mycon = gzcon(gzfile(paste(dir, \"robust_traces.csv.gz\", sep=\"/\"), open=\"r\"))\n",
      "robust_program_events = read.csv(textConnection(readLines(mycon)), sep=\"\\t\", header = F)\n",
      "\n",
      "print(nrow(robust_program_events))\n",
      "print(nrow(buggy_program_events))\n",
      "\n",
      "programs = c(levels(buggy_program_events[,1]),levels(robust_program_events[,1]))\n",
      "cats = factor(c(robust_program_events[,4], buggy_program_events[,4]), levels = c(\"R\",\"B\"))\n",
      "\n",
      "#write.csv(programs,paste(dir,\"programs.csv\", sep=\"/\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "[1] 182\n",
        "[1] 546\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO: Add an explanation about program traces as documents.\n",
      "\n",
      "Now, we load the tm package and create the corpuses from the \"documents\". "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "library(tm)\n",
      "\n",
      "mut_corpus = Corpus(VectorSource(c(robust_program_events[,2],buggy_program_events[,2])))\n",
      "evs_corpus = Corpus(VectorSource(c(robust_program_events[,3],buggy_program_events[,3])))\n",
      "\n",
      "print(mut_corpus)\n",
      "print(evs_corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "A corpus with 728 text documents\n",
        "A corpus with 728 text documents\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, it is time to create the document matrixes, and convert them to data frames adding its correspondent classes. The function \"inspect\" to convert the document term matrix into a data frame prints some information that we don't care, so we discard printed messages in this step."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "#library(\"RWeka\")\n",
      "#options(mc.cores=1)\n",
      "\n",
      "\n",
      "mut_dm = DocumentTermMatrix(mut_corpus)\n",
      "\n",
      "sink(\"/dev/null\")\n",
      "\n",
      "mut_dm_df =  as.data.frame(inspect(mut_dm))\n",
      "rownames(mut_dm_df) = 1:nrow(mut_dm)\n",
      "mut_dm_df[\"class\"] = cats\n",
      "\n",
      "sink()\n",
      "\n",
      "#BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2, delimiters=\" \"))\n",
      "evs_dm = DocumentTermMatrix(evs_corpus, control = list(bounds = list(global = c(1,Inf))))#, tokenize = BigramTokenizer))\n",
      "print(evs_dm)\n",
      "\n",
      "sink(\"/dev/null\")\n",
      "\n",
      "sorted_dm = sort(colSums(as.matrix(evs_dm)), decreasing=TRUE)\n",
      "\n",
      "evs_dm_df =  (as.data.frame(inspect(evs_dm)))\n",
      "#rownames(evs_dm_df) = 1:nrow(evs_dm)\n",
      "#evs_dm_df = evs_dm_df[,cols]\n",
      "#print(2)\n",
      "evs_dm_df[\"class\"] = cats\n",
      "\n",
      "sink()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "A document-term matrix (728 documents, 782 terms)\n",
        "\n",
        "Non-/sparse entries: 27754/541542\n",
        "Sparsity           : 95%\n",
        "Maximal term length: 36 \n",
        "Weighting          : term frequency (tf)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To finish preparing the data, we need make sure we are using the same variables for all the corpuses in the mutation and events data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "# Mutation data\n",
      "\n",
      "mut_robust_cases = mut_dm_df[mut_dm_df$class == \"R\",]\n",
      "mut_buggy_cases  = mut_dm_df[mut_dm_df$class == \"B\",]\n",
      "\n",
      "# Event data\n",
      "\n",
      "evs_robust_cases = evs_dm_df[evs_dm_df$class == \"R\",]\n",
      "evs_buggy_cases  = evs_dm_df[evs_dm_df$class == \"B\",]\n",
      "\n",
      "both_robust_cases = cbind(mut_robust_cases[,names(mut_robust_cases) != \"class\"], evs_robust_cases)\n",
      "both_buggy_cases = cbind(mut_buggy_cases[,names(mut_buggy_cases) != \"class\"], evs_buggy_cases)\n",
      "\n",
      "print(nrow(both_robust_cases))\n",
      "print(nrow(both_buggy_cases))\n",
      "\n",
      "print(ncol(both_robust_cases))\n",
      "print(ncol(both_buggy_cases))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "[1] 397\n",
        "[1] 331\n",
        "[1] 1362\n",
        "[1] 1362\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "robust_cases = both_robust_cases\n",
      "buggy_cases = both_buggy_cases\n",
      "\n",
      "#rm(buggy_program_events)\n",
      "#gc()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "now, we are ready to select train and test.."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "train_size = 250\n",
      "test_size = nrow(buggy_cases) - train_size\n",
      "\n",
      "print(train_size)\n",
      "print(test_size)\n",
      "\n",
      "n = nrow(buggy_cases)\n",
      "rsample = sample(n)\n",
      "\n",
      "train_sample = rsample[1:(train_size)] \n",
      "test_sample = rsample[(train_size+1):(train_size+test_size)]\n",
      "\n",
      "#print(rsample)\n",
      "\n",
      "buggy_train = buggy_cases[train_sample,]\n",
      "buggy_test  = buggy_cases[test_sample,]\n",
      "\n",
      "print(nrow(buggy_train))\n",
      "print(nrow(buggy_test))\n",
      "\n",
      "# robust train and test\n",
      "\n",
      "n = nrow(robust_cases)\n",
      "rsample = sample(n)\n",
      "\n",
      "#print(rsample)\n",
      "\n",
      "# n cases are selected to keep the train dataset balanced\n",
      "train_sample = rsample[1:(train_size)]\n",
      "test_sample =  rsample[(train_size+1):(train_size+test_size)]\n",
      "more_test_sample = rsample[(train_size+test_size+1):n]\n",
      "\n",
      "robust_train = robust_cases[train_sample,]\n",
      "robust_test  = robust_cases[test_sample,]\n",
      "robust_more_test = robust_cases[more_test_sample,]\n",
      "\n",
      "print(nrow(robust_train))\n",
      "print(nrow(robust_test))\n",
      "\n",
      "train = rbind(buggy_train, robust_train)\n",
      "test  = rbind(buggy_test, robust_test)\n",
      "#more_test = robust_more_test\n",
      "\n",
      "xy_train = train\n",
      "#xy_train[,\"class\"] = factor(train[,\"class\"])\n",
      "x_test = test[,names(test) != \"class\"]\n",
      "y_test  = test[,\"class\"]\n",
      "\n",
      "#print(more_test[1,])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "[1] 250\n",
        "[1] 81\n",
        "[1] 250\n",
        "[1] 81\n",
        "[1] 250\n",
        "[1] 81\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, we are ready to train and test a knn model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "mycon = gzcon(gzfile(paste(dir, \"filtered_traces.csv.gz\", sep=\"/\"), open=\"r\"))\n",
      "more_program_events = read.csv(textConnection(readLines(mycon)), sep=\"\\t\", header = F)\n",
      "\n",
      "cats = factor(more_program_events[,4], levels = c(\"R\",\"B\"))\n",
      "\n",
      "mut_more_corpus = Corpus(VectorSource(more_program_events[,2]))\n",
      "evs_more_corpus = Corpus(VectorSource(more_program_events[,3]))\n",
      "\n",
      "mut_more_dm  = DocumentTermMatrix(mut_more_corpus)\n",
      "evs_more_dm  = DocumentTermMatrix(evs_more_corpus)\n",
      "\n",
      "print(evs_more_dm)\n",
      "\n",
      "sink(\"/dev/null\")\n",
      "\n",
      "mut_more_dm_df =  as.data.frame(inspect(mut_more_dm))\n",
      "mut_more_dm_df[\"class\"] = cats\n",
      "\n",
      "evs_more_dm_df =  (as.data.frame(inspect(evs_more_dm)))\n",
      "evs_more_dm_df[\"class\"] = cats\n",
      "    \n",
      "sink()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "A document-term matrix (2333 documents, 1026 terms)\n",
        "\n",
        "Non-/sparse entries: 61664/2331994\n",
        "Sparsity           : 97%\n",
        "Maximal term length: 34 \n",
        "Weighting          : term frequency (tf)\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "gc()\n",
      "\n",
      "more_cases = cbind(mut_more_dm_df[,names(mut_more_dm_df) != \"class\"], evs_more_dm_df)\n",
      "\n",
      "robust_cases = more_cases[more_cases$class == \"R\",]\n",
      "buggy_cases = more_cases[more_cases$class == \"B\",]\n",
      "\n",
      "#mut_robust_cases = mut_more_dm_df[mut_more_dm_df$class == \"R\",]\n",
      "#mut_buggy_cases = mut_more_dm_df[mut_more_dm_df$class == \"B\",]\n",
      "\n",
      "#evs_robust_cases = evs_more_dm_df[more_dm_df$class == \"R\",]\n",
      "#evs_buggy_cases  = evs_more_dm_df[more_dm_df$class == \"B\",]\n",
      "\n",
      "#robust_cases = cbind(mut_more_dm_df[,names(mut_more_dm_df) != \"class\"], evs_more_dm_df)\n",
      "\n",
      "n = nrow(robust_cases)\n",
      "\n",
      "rsample = sample(nrow(robust_cases))\n",
      "robust_cases = robust_cases[rsample[1:n],]\n",
      "\n",
      "rsample = sample(nrow(buggy_cases))\n",
      "buggy_cases = buggy_cases[rsample[1:n],]\n",
      "\n",
      "print(nrow(robust_cases))\n",
      "print(nrow(buggy_cases))\n",
      "\n",
      "more_test = rbind(robust_cases, buggy_cases)\n",
      "\n",
      "x_more_test = more_test[,names(more_test) != \"class\"]\n",
      "y_more_test  = more_test[,\"class\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "[1] 837\n",
        "[1] 837\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "xy_train_vars = names(xy_train)\n",
      "x_more_test_vars = names(x_more_test)\n",
      "\n",
      "#print(x_more_test_vars)\n",
      "\n",
      "xy_train_vars = xy_train_vars[xy_train_vars != \"class\"]\n",
      "missing_vars = xy_train_vars[! xy_train_vars %in% x_more_test_vars]\n",
      "x_more_test[,missing_vars] = 0\n",
      "#print(missing_vars)\n",
      "\n",
      "missing_vars = names(more_test)[!(names(more_test) %in% names(xy_train))]\n",
      "missing_vars = missing_vars[missing_vars != \"class\"]\n",
      "#print(names(more_test))\n",
      "#print()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "or a SVM .."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "#library(\"e1071\")\n",
      "#library(\"caret\")\n",
      "\n",
      "#print(names(tail(sorted_dm, -700)))\n",
      "\n",
      "for (n in c(0)){#seq(25,100,25)){\n",
      "  exc_vars = names(sorted_dm)#names(tail(sorted_dm, -n))\n",
      "  inc_vars = names(xy_train)[!(names(xy_train) %in% exc_vars)]\n",
      "  \n",
      "  #m = svm(class ~., data=xy_train[,inc_vars], gamma=0.001, cost=100)\n",
      "  m = svm(class ~., data=more_test, gamma=0.001, cost=100)\n",
      "  #m = tune.svm(class~., data = more_test,  gamma = 10^(-5:-1), cost = 10^(1:2))\n",
      "  #print(summary(m))\n",
      "  #m = m$best.model\n",
      "  \n",
      "  x_test_aug = xy_train\n",
      "  x_test_aug[,missing_vars] = 0\n",
      "  \n",
      "  z = predict(m,x_test_aug)\n",
      "  \n",
      "  #print(m)\n",
      "  print(n)\n",
      "  print(confusionMatrix(table(pred=z, true=xy_train[,\"class\"]))$overall[1])\n",
      "  \n",
      "  #z = predict(m,x_more_test)\n",
      "  #print(confusionMatrix(table(pred=z, true=y_more_test))$overall[1])\n",
      "}\n",
      "\n",
      "print(warning())\n",
      "\n",
      "#x_more_test = more_test[,names(test) != \"class\"]\n",
      "#y_more_test  = more_test[,\"class\"]\n",
      "\n",
      "#m = svm(class ~., data=xy_train, gamma=0.1, cost=10)#, kernel=\"linear\")\n",
      "#m = svm(class ~., data=xy_train, gamma=0.001, cost=100)#, kernel=\"linear\")\n",
      "\n",
      "#m = tune.svm(class~., data = xy_train,  gamma = 10^(-5:-1), cost = 10^(1:2))\n",
      "#print(summary(m))\n",
      "#m = m$best.model\n",
      "\n",
      "#m = svm(class ~., data=xy_train, gamma=0.01, cost=100)#, kernel=\"linear\")\n",
      "\n",
      "#z = predict(m,x_test)\n",
      "#print(z)\n",
      "#print(y_test)\n",
      "#print(confusionMatrix(table(pred=z, true=y_test)))\n",
      "\n",
      "#z = predict(m,x_more_test)\n",
      "#print(z)\n",
      "#print(confusionMatrix(table(pred=z, true=y_more_test)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "[1] 0\n",
        "Accuracy \n",
        "    0.55 \n",
        "[1] \"\"\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "\n",
      "scores = t(abs(t(m$coefs) %*% m$SV))\n",
      "inds = sort(scores, decreasing=TRUE, index.return = TRUE)$i\n",
      "print(names(scores[inds,][1:50]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        " [1] \"X.strlen.ret_val.num32b8.\"          \"X.strlen.0.hptr32.\"                \n",
        " [3] \"X.strchr.1.num32b8.\"                \"X.strchr.0.lptr32.\"                \n",
        " [5] \"X.strcpy.ret_val.hptr32.\"           \"X.strcpy.0.hptr32.\"                \n",
        " [7] \"X.strlen.0.gptr32.\"                 \"X.memcpy.1.hptr32.\"                \n",
        " [9] \"X.strcpy.1.hptr32.\"                 \"X.strchr.ret_val.nptr32.\"          \n",
        "[11] \"X.__ctype_b_loc.ret_val.fptr32.\"    \"X.__ctype_b_loc.0.top32.\"          \n",
        "[13] \"X.memcpy.0.hptr32.\"                 \"X.memcpy.ret_val.hptr32.\"          \n",
        "[15] \"X.memcpy.2.num32b8.\"                \"X._io_getc.ret_val.num32b8.\"       \n",
        "[17] \"X.strchr.ret_val.lptr32.\"           \"X.fread.1.num32b8.\"                \n",
        "[19] \"X.fread.3.hptr32.\"                  \"X.fread.2.num32b8.\"                \n",
        "[21] \"X.fread.0.sptr32.\"                  \"X.fread.ret_val.num32b0.\"          \n",
        "[23] \"X.strlen.0.lptr32.\"                 \"X.tolower.0.num32b8.\"              \n",
        "[25] \"X.tolower.ret_val.num32b8.\"         \"X._io_getc.0.hptr32.\"              \n",
        "[27] \"X.memcpy.1.lptr32.\"                 \"X.realloc.ret_val.hptr32.\"         \n",
        "[29] \"X.realloc.1.num32b8.\"               \"X.strcmp.0.hptr32.\"                \n",
        "[31] \"X.memset.0.hptr32.\"                 \"X.memset.ret_val.hptr32.\"          \n",
        "[33] \"X.realloc.0.nptr32.\"                \"X.memset.2.num32b16.\"              \n",
        "[35] \"X.memset.1.num32b0.\"                \"X.__errno_location.0.top32.\"       \n",
        "[37] \"X.__errno_location.ret_val.fptr32.\" \"X.fgets.0.sptr32.\"                 \n",
        "[39] \"X.fgets.ret_val.sptr32.\"            \"X.fgets.2.hptr32.\"                 \n",
        "[41] \"X.fgets.1.num32b16.\"                \"X.strcmp.1.sptr32.\"                \n",
        "[43] \"X.vfprintf.0.lptr32.\"               \"X.vfprintf.2.sptr32.\"              \n",
        "[45] \"X.vfprintf.ret_val.num32b8.\"        \"X.fprintf.1.gptr32.\"               \n",
        "[47] \"X.vfprintf.1.gptr32.\"               \"X.fprintf.0.lptr32.\"               \n",
        "[49] \"X.fputc.0.num32b8.\"                 \"X.fputc.1.lptr32.\"                 \n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "m_vars = names(xy_train)\n",
      "\n",
      "save(m_vars, file=paste(dir, \"svms\", \"mvars.data\", sep=\"/\"))\n",
      "save(m, file=paste(dir, \"svms\", \"mutation-event-classifier.svm\", sep=\"/\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}